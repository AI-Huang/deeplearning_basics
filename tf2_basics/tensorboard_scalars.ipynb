{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599487165526",
   "display_name": "Python 3.7.7 64-bit ('tf2': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 加载 TensorBoard notebook 插件\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "TensorFlow version:  2.3.0\n"
    }
   ],
   "source": [
    "# @RefLink: https://www.tensorflow.org/tensorboard/scalars_and_keras?hl=zh-cn\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from utils.dir_utils import makedir_exist_ok\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "    \"This notebook requires TensorFlow 2.0 or above.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 1000\n",
    "# 80% 的数据用来训练\n",
    "train_pct = 0.8\n",
    "\n",
    "train_size = int(data_size * train_pct)\n",
    "\n",
    "# 创建在(-1,1)范围内的随机数作为输入\n",
    "x = np.linspace(-1, 1, data_size)\n",
    "np.random.shuffle(x)\n",
    "\n",
    "# 生成输出数据\n",
    "# y = 0.5x + 2 + noise\n",
    "y = 0.5 * x + 2 + np.random.normal(0, 0.05, (data_size, ))\n",
    "\n",
    "# 将数据分成训练和测试集\n",
    "x_train, y_train = x[:train_size], y[:train_size]\n",
    "x_test, y_test = x[train_size:], y[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging custom scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From C:\\Users\\kellyhwong\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\nInstructions for updating:\nuse `tf.profiler.experimental.stop` instead.\nTraining ... With default parameters, this takes less than 10 seconds.\nAverage test loss:  0.0026170198270119727\n"
    }
   ],
   "source": [
    "log_dir = \"./logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "makedir_exist_ok(log_dir)\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "\n",
    "# Logging custom scalars\n",
    "file_writer = tf.summary.create_file_writer(log_dir + \"/metrics\")\n",
    "file_writer.set_as_default()\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "  \"\"\"\n",
    "  Returns a custom learning rate that decreases as epochs progress.\n",
    "  \"\"\"\n",
    "  learning_rate = 0.2\n",
    "  if epoch > 10:\n",
    "    learning_rate = 0.02\n",
    "  if epoch > 20:\n",
    "    learning_rate = 0.01\n",
    "  if epoch > 50:\n",
    "    learning_rate = 0.005\n",
    "  # see https://www.tensorflow.org/tensorboard/scalars_and_keras\n",
    "  # Inside the learning rate function, use tf.summary.scalar() to log the custom learning rate.\n",
    "  tf.summary.scalar('learning rate', data=learning_rate, step=epoch)\n",
    "  return learning_rate\n",
    "\n",
    "lr_callback = keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(16, input_dim=1),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss='mse', # keras.losses.mean_squared_error\n",
    "    optimizer=keras.optimizers.SGD(),\n",
    ")\n",
    "\n",
    "print(\"Training ... With default parameters, this takes less than 10 seconds.\")\n",
    "training_history = model.fit(\n",
    "    x_train, # input\n",
    "    y_train, # output\n",
    "    batch_size=train_size,\n",
    "    verbose=0, # Suppress chatty output; use Tensorboard instead\n",
    "    epochs=100,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[tensorboard_callback, lr_callback],\n",
    ")\n",
    "\n",
    "print(\"Average test loss: \", np.average(training_history.history['loss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 记录自定义 scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Reusing TensorBoard on port 6006 (pid 12224), started 6:36:45 ago. (Use '!kill 12224' to kill it.)"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/scalars"
   ]
  }
 ]
}